{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import scipy.optimize as spopt\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Pose Embedder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullBodyPoseEmbedder(object):\n",
    "  \"\"\"Converts 3D pose landmarks into 3D embedding.\"\"\"\n",
    "\n",
    "  def __init__(self, torso_size_multiplier=2.5):\n",
    "    # Multiplier to apply to the torso to get minimal body size.\n",
    "    self._torso_size_multiplier = torso_size_multiplier\n",
    "\n",
    "    # Names of the landmarks as they appear in the prediction.\n",
    "    self._landmark_names = [\n",
    "        'nose',\n",
    "        'left_eye_inner', 'left_eye', 'left_eye_outer',\n",
    "        'right_eye_inner', 'right_eye', 'right_eye_outer',\n",
    "        'left_ear', 'right_ear',\n",
    "        'mouth_left', 'mouth_right',\n",
    "        'left_shoulder', 'right_shoulder',\n",
    "        'left_elbow', 'right_elbow',\n",
    "        'left_wrist', 'right_wrist',\n",
    "        'left_pinky_1', 'right_pinky_1',\n",
    "        'left_index_1', 'right_index_1',\n",
    "        'left_thumb_2', 'right_thumb_2',\n",
    "        'left_hip', 'right_hip',\n",
    "        'left_knee', 'right_knee',\n",
    "        'left_ankle', 'right_ankle',\n",
    "        'left_heel', 'right_heel',\n",
    "        'left_foot_index', 'right_foot_index',\n",
    "    ]\n",
    "\n",
    "    def __call__(self, landmarks):\n",
    "        \"\"\"Normalizes pose landmarks and converts to embedding\n",
    "\n",
    "        Args:\n",
    "          landmarks - NumPy array with 3D landmarks of shape (N, 3).\n",
    "\n",
    "        Result:\n",
    "          Numpy array with pose embedding of shape (M, 3) where `M` is the number of\n",
    "          pairwise distances defined in `_get_pose_distance_embedding`.\n",
    "        \"\"\"\n",
    "        assert landmarks.shape[0] == len(self._landmark_names), 'Unexpected number of landmarks: {}'.format(landmarks.shape[0])\n",
    "\n",
    "        # Get pose landmarks.\n",
    "        landmarks = np.copy(landmarks)\n",
    "\n",
    "        # Normalize landmarks.\n",
    "        landmarks = self._normalize_pose_landmarks(landmarks)\n",
    "\n",
    "        # Get embedding.\n",
    "        embedding = self._get_pose_distance_embedding(landmarks)\n",
    "\n",
    "        return embedding\n",
    "\n",
    "    def _normalize_pose_landmarks(self, landmarks):\n",
    "        \"\"\"Normalizes landmarks translation and scale.\"\"\"\n",
    "        landmarks = np.copy(landmarks)\n",
    "\n",
    "        # Normalize translation.\n",
    "        pose_center = self._get_pose_center(landmarks)\n",
    "        landmarks -= pose_center\n",
    "\n",
    "        # Normalize scale.\n",
    "        pose_size = self._get_pose_size(landmarks, self._torso_size_multiplier)\n",
    "        landmarks /= pose_size\n",
    "        # Multiplication by 100 is not required, but makes it eaasier to debug.\n",
    "        landmarks *= 100\n",
    "\n",
    "        return landmarks\n",
    "\n",
    "    def _get_pose_center(self, landmarks):\n",
    "        \"\"\"Calculates pose center as point between hips.\"\"\"\n",
    "        left_hip = landmarks[self._landmark_names.index('left_hip')]\n",
    "        right_hip = landmarks[self._landmark_names.index('right_hip')]\n",
    "        center = (left_hip + right_hip) * 0.5\n",
    "        return center\n",
    "\n",
    "    def _get_pose_size(self, landmarks, torso_size_multiplier):\n",
    "        \"\"\"Calculates pose size.\n",
    "\n",
    "        It is the maximum of two values:\n",
    "          * Torso size multiplied by `torso_size_multiplier`\n",
    "          * Maximum distance from pose center to any pose landmark\n",
    "        \"\"\"\n",
    "        # This approach uses only 2D landmarks to compute pose size.\n",
    "        landmarks = landmarks[:, :2]\n",
    "\n",
    "        # Hips center.\n",
    "        left_hip = landmarks[self._landmark_names.index('left_hip')]\n",
    "        right_hip = landmarks[self._landmark_names.index('right_hip')]\n",
    "        hips = (left_hip + right_hip) * 0.5\n",
    "\n",
    "        # Shoulders center.\n",
    "        left_shoulder = landmarks[self._landmark_names.index('left_shoulder')]\n",
    "        right_shoulder = landmarks[self._landmark_names.index('right_shoulder')]\n",
    "        shoulders = (left_shoulder + right_shoulder) * 0.5\n",
    "\n",
    "        # Torso size as the minimum body size.\n",
    "        torso_size = np.linalg.norm(shoulders - hips)\n",
    "\n",
    "        # Max dist to pose center.\n",
    "        pose_center = self._get_pose_center(landmarks)\n",
    "        max_dist = np.max(np.linalg.norm(landmarks - pose_center, axis=1))\n",
    "\n",
    "        return max(torso_size * torso_size_multiplier, max_dist)\n",
    "\n",
    "    def _get_pose_distance_embedding(self, landmarks):\n",
    "        \"\"\"Converts pose landmarks into 3D embedding.\n",
    "\n",
    "        We use several pairwise 3D distances to form pose embedding. All distances\n",
    "        include X and Y components with sign. We differnt types of pairs to cover\n",
    "        different pose classes. Feel free to remove some or add new.\n",
    "\n",
    "        Args:\n",
    "          landmarks - NumPy array with 3D landmarks of shape (N, 3).\n",
    "\n",
    "        Result:\n",
    "          Numpy array with pose embedding of shape (M, 3) where `M` is the number of\n",
    "          pairwise distances.\n",
    "        \"\"\"\n",
    "        embedding = np.array([\n",
    "            # One joint.\n",
    "\n",
    "            self._get_distance(\n",
    "                self._get_average_by_names(landmarks, 'left_hip', 'right_hip'),\n",
    "                self._get_average_by_names(landmarks, 'left_shoulder', 'right_shoulder')),\n",
    "\n",
    "            self._get_distance_by_names(landmarks, 'left_shoulder', 'left_elbow'),\n",
    "            self._get_distance_by_names(landmarks, 'right_shoulder', 'right_elbow'),\n",
    "\n",
    "            self._get_distance_by_names(landmarks, 'left_elbow', 'left_wrist'),\n",
    "            self._get_distance_by_names(landmarks, 'right_elbow', 'right_wrist'),\n",
    "\n",
    "            self._get_distance_by_names(landmarks, 'left_hip', 'left_knee'),\n",
    "            self._get_distance_by_names(landmarks, 'right_hip', 'right_knee'),\n",
    "\n",
    "            self._get_distance_by_names(landmarks, 'left_knee', 'left_ankle'),\n",
    "            self._get_distance_by_names(landmarks, 'right_knee', 'right_ankle'),\n",
    "\n",
    "            # Two joints.\n",
    "\n",
    "            self._get_distance_by_names(landmarks, 'left_shoulder', 'left_wrist'),\n",
    "            self._get_distance_by_names(landmarks, 'right_shoulder', 'right_wrist'),\n",
    "\n",
    "            self._get_distance_by_names(landmarks, 'left_hip', 'left_ankle'),\n",
    "            self._get_distance_by_names(landmarks, 'right_hip', 'right_ankle'),\n",
    "\n",
    "            # Four joints.\n",
    "\n",
    "            self._get_distance_by_names(landmarks, 'left_hip', 'left_wrist'),\n",
    "            self._get_distance_by_names(landmarks, 'right_hip', 'right_wrist'),\n",
    "\n",
    "            # Five joints.\n",
    "\n",
    "            self._get_distance_by_names(landmarks, 'left_shoulder', 'left_ankle'),\n",
    "            self._get_distance_by_names(landmarks, 'right_shoulder', 'right_ankle'),\n",
    "\n",
    "            self._get_distance_by_names(landmarks, 'left_hip', 'left_wrist'),\n",
    "            self._get_distance_by_names(landmarks, 'right_hip', 'right_wrist'),\n",
    "\n",
    "            # Cross body.\n",
    "\n",
    "            self._get_distance_by_names(landmarks, 'left_elbow', 'right_elbow'),\n",
    "            self._get_distance_by_names(landmarks, 'left_knee', 'right_knee'),\n",
    "\n",
    "            self._get_distance_by_names(landmarks, 'left_wrist', 'right_wrist'),\n",
    "            self._get_distance_by_names(landmarks, 'left_ankle', 'right_ankle'),\n",
    "\n",
    "            # Body bent direction.\n",
    "\n",
    "            # self._get_distance(\n",
    "            #     self._get_average_by_names(landmarks, 'left_wrist', 'left_ankle'),\n",
    "            #     landmarks[self._landmark_names.index('left_hip')]),\n",
    "            # self._get_distance(\n",
    "            #     self._get_average_by_names(landmarks, 'right_wrist', 'right_ankle'),\n",
    "            #     landmarks[self._landmark_names.index('right_hip')]),\n",
    "        ])\n",
    "\n",
    "        return embedding\n",
    "\n",
    "    def _get_average_by_names(self, landmarks, name_from, name_to):\n",
    "        lmk_from = landmarks[self._landmark_names.index(name_from)]\n",
    "        lmk_to = landmarks[self._landmark_names.index(name_to)]\n",
    "        return (lmk_from + lmk_to) * 0.5\n",
    "\n",
    "    def _get_distance_by_names(self, landmarks, name_from, name_to):\n",
    "        lmk_from = landmarks[self._landmark_names.index(name_from)]\n",
    "        lmk_to = landmarks[self._landmark_names.index(name_to)]\n",
    "        return self._get_distance(lmk_from, lmk_to)\n",
    "\n",
    "    def _get_distance(self, lmk_from, lmk_to):\n",
    "        return lmk_to - lmk_from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"set/path/to/location/of/csv/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update classes and class map to reflect pose set\n",
    "classes = ['circle','handsShoulders','sideT','hips','Vdown','track'] \n",
    "class_map = {1:'circle',2:'handsShoulders',3:'sideT',4:'hips',5:'Vdown',6:'track'}\n",
    "\n",
    "class_num = 1\n",
    "merge = []\n",
    "for cl in classes:\n",
    "    df = pd.read_csv(f'{path}/{cl}.csv',header=None) # Put absolute path\n",
    "    df['Class'] = class_num\n",
    "    class_num+=1\n",
    "    merge.append(df)\n",
    "data_final = pd.concat(merge,ignore_index=True)\n",
    "\n",
    "# Filter Data\n",
    "filt = [x for x in data_final.columns if x in range(1,102,1)] + ['Class']\n",
    "data_and_labels = data_final[filt]\n",
    "for i in range(10):\n",
    "    data_and_labels = data_and_labels.sample(frac=1) # shuffle data\n",
    "\n",
    "# Reshape data and create embedding\n",
    "data_filt = [x for x in data_and_labels.columns if x in range(1,100,1)]\n",
    "data = data_and_labels[data_filt]\n",
    "data = data.to_numpy()\n",
    "embed = FullBodyPoseEmbedder()\n",
    "arrays = []\n",
    "for i in range(len(data)):\n",
    "    temp = data[i,:] # isolate single example\n",
    "    temp = temp.reshape((33,3)) # reshape to landmark output dimensions\n",
    "    temp = embed(temp)\n",
    "    temp = temp.flatten()\n",
    "    arrays.append(temp)\n",
    "data = np.stack(arrays, axis=0)\n",
    "\n",
    "# break up data\n",
    "train_data = data[0:int(len(data)*.7)]\n",
    "test_data = data[int(len(data)*.7):]\n",
    "label_filt = ['Class']\n",
    "labels = data_and_labels[label_filt]\n",
    "labels = labels.to_numpy()\n",
    "labels = labels.reshape(len(labels),)\n",
    "train_labels = labels[0:int(len(data)*.7)]\n",
    "test_labels = labels[int(len(data)*.7):]\n",
    "print(np.unique(train_labels))\n",
    "print(np.unique(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "# Separate the digits into labels\n",
    "inds=np.array([train_labels==i for i in range(len(classes))])\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20, whiten=True)\n",
    "pca.fit(train_data)\n",
    "sk_pose_reduced=pca.transform(train_data)\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(len(classes)):\n",
    "    plt.plot(sk_pose_reduced[inds[i],0],\n",
    "             sk_pose_reduced[inds[i],1],\n",
    "             'o', label=str(class_map[i+1]), alpha=0.5)\n",
    "plt.gca().legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(max_iter=1000)\n",
    "logisticRegr.fit(train_data, train_labels) # if the algorithm did not converge, try increase iteration number by specifying \"max_iter\"\n",
    "\n",
    "s = time.time()\n",
    "print(logisticRegr.predict(test_data[0].reshape(1,-1))[0])\n",
    "print(test_labels[0])\n",
    "e = time.time()\n",
    "print(e-s)\n",
    "\n",
    "# Make predictions on entire test data\n",
    "predictions = logisticRegr.predict(test_data)\n",
    "score = logisticRegr.score(test_data, test_labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Classifier as .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pkl_filename = f\"{path}/LogReg_pose_classifier.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(logisticRegr, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
